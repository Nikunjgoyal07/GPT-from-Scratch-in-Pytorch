{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":452405,"sourceType":"modelInstanceVersion","modelInstanceId":366980,"modelId":387884}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"d52c6d41-fe53-4af6-ba32-86d678e5304f","_cell_guid":"05f37852-dd9d-433e-91d5-66f908397f9b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-29T07:28:47.271785Z","iopub.execute_input":"2025-06-29T07:28:47.272291Z","iopub.status.idle":"2025-06-29T07:28:47.555781Z","shell.execute_reply.started":"2025-06-29T07:28:47.272271Z","shell.execute_reply":"2025-06-29T07:28:47.55506Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt","metadata":{"_uuid":"26e22b2d-c470-42fd-9e1e-ff9b48b76f14","_cell_guid":"14c47a4e-24ed-4a4f-b41c-fe95c7d9bc53","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:09.685987Z","iopub.execute_input":"2025-07-20T13:27:09.686790Z","iopub.status.idle":"2025-07-20T13:27:10.032546Z","shell.execute_reply.started":"2025-07-20T13:27:09.686767Z","shell.execute_reply":"2025-07-20T13:27:10.031416Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"--2025-07-20 13:27:09--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1115394 (1.1M) [text/plain]\nSaving to: ‘input.txt.2’\n\ninput.txt.2         100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n\n2025-07-20 13:27:09 (22.8 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n\n","output_type":"stream"}],"execution_count":249},{"cell_type":"code","source":"with open('input.txt', 'r', encoding='utf-8') as f:\n    text = f.read()","metadata":{"_uuid":"86353448-cccc-45ed-9404-9d38a5d803ff","_cell_guid":"7658a502-44a3-47bb-b67e-d8051c41b48a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:10.033813Z","iopub.execute_input":"2025-07-20T13:27:10.034153Z","iopub.status.idle":"2025-07-20T13:27:10.040062Z","shell.execute_reply.started":"2025-07-20T13:27:10.034102Z","shell.execute_reply":"2025-07-20T13:27:10.039392Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":250},{"cell_type":"code","source":"print(\"length of dataset in characters: \", len(text))","metadata":{"_uuid":"1c36002e-5fdb-411e-94d6-f327c519f8bf","_cell_guid":"48ca315a-2033-4044-b55d-db140cd56be8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:10.040928Z","iopub.execute_input":"2025-07-20T13:27:10.041716Z","iopub.status.idle":"2025-07-20T13:27:10.054676Z","shell.execute_reply.started":"2025-07-20T13:27:10.041692Z","shell.execute_reply":"2025-07-20T13:27:10.053905Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"length of dataset in characters:  1115394\n","output_type":"stream"}],"execution_count":251},{"cell_type":"code","source":"print(text[:1000])","metadata":{"_uuid":"bd958e8d-6017-4da6-bc9e-dae51d5f91a9","_cell_guid":"83ac2ed5-0000-43c3-8a48-d864868e8378","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:10.055563Z","iopub.execute_input":"2025-07-20T13:27:10.055892Z","iopub.status.idle":"2025-07-20T13:27:10.070121Z","shell.execute_reply.started":"2025-07-20T13:27:10.055870Z","shell.execute_reply":"2025-07-20T13:27:10.069454Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n\n","output_type":"stream"}],"execution_count":252},{"cell_type":"code","source":"!pip install nltk","metadata":{"_uuid":"71fa935a-f7f1-48a0-b71e-98779e33460d","_cell_guid":"02744e72-7e2c-44e4-aaa7-4c16839094fa","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:10.070826Z","iopub.execute_input":"2025-07-20T13:27:10.071131Z","iopub.status.idle":"2025-07-20T13:27:13.123252Z","shell.execute_reply.started":"2025-07-20T13:27:10.071105Z","shell.execute_reply":"2025-07-20T13:27:13.121885Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","output_type":"stream"}],"execution_count":253},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom collections import Counter\nfrom torch.utils.data import Dataset, DataLoader\nfrom nltk.tokenize import word_tokenize\nimport nltk","metadata":{"_uuid":"26bb3a05-20a6-46d1-ae16-88872fce8312","_cell_guid":"9c39d349-e5e2-443e-9109-39a25a2b1d7d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:13.125328Z","iopub.execute_input":"2025-07-20T13:27:13.125772Z","iopub.status.idle":"2025-07-20T13:27:13.132159Z","shell.execute_reply.started":"2025-07-20T13:27:13.125737Z","shell.execute_reply":"2025-07-20T13:27:13.131334Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":254},{"cell_type":"code","source":"# Tokenization\nnltk.download('punkt')\nnltk.download('punkt_tab')","metadata":{"_uuid":"c5c90969-dd31-4e81-9631-74d25e5b2336","_cell_guid":"4a63d6ec-2bdd-4ece-9a59-720294aee361","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:13.132738Z","iopub.execute_input":"2025-07-20T13:27:13.132982Z","iopub.status.idle":"2025-07-20T13:27:13.152695Z","shell.execute_reply.started":"2025-07-20T13:27:13.132961Z","shell.execute_reply":"2025-07-20T13:27:13.151912Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"},{"execution_count":255,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":255},{"cell_type":"code","source":"# tokenize\ntokens = word_tokenize(text.lower())","metadata":{"_uuid":"baddefc6-0d63-46a3-943c-b950bcb7b032","_cell_guid":"04d8fcd5-11f4-4b4f-9d59-419c489fec71","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:13.153596Z","iopub.execute_input":"2025-07-20T13:27:13.153838Z","iopub.status.idle":"2025-07-20T13:27:14.320670Z","shell.execute_reply.started":"2025-07-20T13:27:13.153816Z","shell.execute_reply":"2025-07-20T13:27:14.320134Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":256},{"cell_type":"code","source":"vocab = {'<unk>':0}\nfor token in Counter(tokens).keys():\n    if token not in vocab:\n        vocab[token] = len(vocab)","metadata":{"_uuid":"2ef7d5b4-0635-4ecc-b40d-3de9a29f175e","_cell_guid":"1590fe2b-b052-460a-833d-6779347b29c7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:14.321357Z","iopub.execute_input":"2025-07-20T13:27:14.321531Z","iopub.status.idle":"2025-07-20T13:27:14.356308Z","shell.execute_reply.started":"2025-07-20T13:27:14.321517Z","shell.execute_reply":"2025-07-20T13:27:14.355337Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":257},{"cell_type":"code","source":"len(vocab)","metadata":{"_uuid":"cb367df0-1373-4cca-9250-51990f3e8d40","_cell_guid":"56423be5-ecf0-4044-a67a-e12cffceebd1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:14.357207Z","iopub.execute_input":"2025-07-20T13:27:14.357459Z","iopub.status.idle":"2025-07-20T13:27:14.372322Z","shell.execute_reply.started":"2025-07-20T13:27:14.357437Z","shell.execute_reply":"2025-07-20T13:27:14.371605Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":258,"output_type":"execute_result","data":{"text/plain":"12343"},"metadata":{}}],"execution_count":258},{"cell_type":"code","source":"input_sentences = text.split('\\n')","metadata":{"_uuid":"778ae8c4-ba0e-4585-ad7c-aaa8300f3b48","_cell_guid":"bc47f198-9696-4575-993b-e3fc6d351319","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:14.373018Z","iopub.execute_input":"2025-07-20T13:27:14.373255Z","iopub.status.idle":"2025-07-20T13:27:14.392488Z","shell.execute_reply.started":"2025-07-20T13:27:14.373233Z","shell.execute_reply":"2025-07-20T13:27:14.391917Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":259},{"cell_type":"code","source":"len(input_sentences)","metadata":{"_uuid":"219373dd-7a39-415b-8a41-45f70a88298f","_cell_guid":"7a2e6be3-b21e-4840-a45c-d5ba7eb1153e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:14.393273Z","iopub.execute_input":"2025-07-20T13:27:14.393503Z","iopub.status.idle":"2025-07-20T13:27:14.407449Z","shell.execute_reply.started":"2025-07-20T13:27:14.393488Z","shell.execute_reply":"2025-07-20T13:27:14.406783Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":260,"output_type":"execute_result","data":{"text/plain":"40001"},"metadata":{}}],"execution_count":260},{"cell_type":"code","source":"input_sentences = [s for s in input_sentences if s != \"\"]","metadata":{"_uuid":"b0a22cfa-8bb0-4d19-a82e-07e1c93488de","_cell_guid":"c46061a7-3082-4ea6-b5dd-5bf0b11f2826","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:14.408009Z","iopub.execute_input":"2025-07-20T13:27:14.408200Z","iopub.status.idle":"2025-07-20T13:27:14.422715Z","shell.execute_reply.started":"2025-07-20T13:27:14.408186Z","shell.execute_reply":"2025-07-20T13:27:14.422195Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":261},{"cell_type":"code","source":"merged_sentences = []\n\n# pick how many lines to merge — you said 4–5, so we’ll do 5\nchunk_size = 5\n\n# make sure your original list has no empty lines\ninput_sentences = [s.strip() for s in input_sentences if s.strip()]\n\n# loop in steps of `chunk_size`\nfor i in range(0, len(input_sentences), chunk_size):\n    chunk = input_sentences[i:i+chunk_size]\n    merged = ' '.join(chunk)\n    merged_sentences.append(merged)\n\nprint(merged_sentences[:3])  # preview first 3 chunks","metadata":{"_uuid":"71c58e83-e582-4456-b152-6576a3f49a65","_cell_guid":"1d1ad698-604f-443e-932c-c11c45aa9bf4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:14.423433Z","iopub.execute_input":"2025-07-20T13:27:14.423662Z","iopub.status.idle":"2025-07-20T13:27:14.442966Z","shell.execute_reply.started":"2025-07-20T13:27:14.423640Z","shell.execute_reply":"2025-07-20T13:27:14.442267Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"['First Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen:', 'You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people.', \"All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict?\"]\n","output_type":"stream"}],"execution_count":262},{"cell_type":"code","source":"len(merged_sentences)","metadata":{"_uuid":"cf8ff87e-6fdc-44e2-bd08-0f2e0e8e551b","_cell_guid":"1b3d0add-308e-41eb-8969-13527bfa804f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:14.443813Z","iopub.execute_input":"2025-07-20T13:27:14.444054Z","iopub.status.idle":"2025-07-20T13:27:14.457649Z","shell.execute_reply.started":"2025-07-20T13:27:14.444030Z","shell.execute_reply":"2025-07-20T13:27:14.457067Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":263,"output_type":"execute_result","data":{"text/plain":"6556"},"metadata":{}}],"execution_count":263},{"cell_type":"code","source":"merged_sentences[:5]","metadata":{"_uuid":"4fad4ba6-b0d9-4311-9944-5a4c54613fd5","_cell_guid":"2fd3926b-aff4-446d-a2f2-4388843ab011","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:14.458268Z","iopub.execute_input":"2025-07-20T13:27:14.458424Z","iopub.status.idle":"2025-07-20T13:27:14.472522Z","shell.execute_reply.started":"2025-07-20T13:27:14.458412Z","shell.execute_reply":"2025-07-20T13:27:14.471994Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":264,"output_type":"execute_result","data":{"text/plain":"['First Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen:',\n 'You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people.',\n \"All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict?\",\n \"All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen:\",\n 'We are accounted poor citizens, the patricians good. What authority surfeits on would relieve us: if they would yield us but the superfluity, while it were wholesome, we might guess they relieved us humanely; but they think we are too dear: the leanness that']"},"metadata":{}}],"execution_count":264},{"cell_type":"code","source":"def text_to_indices(sentence, vocab):\n\n  numerical_sentence = []\n\n  for token in sentence:\n    if token in vocab:\n      numerical_sentence.append(vocab[token])\n    else:\n      numerical_sentence.append(vocab['<unk>'])\n\n  return numerical_sentence","metadata":{"_uuid":"fcb30e59-822a-4d28-8a4b-9c0a0483b5c5","_cell_guid":"6826c576-138e-4e80-baec-ba511524229d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:14.473277Z","iopub.execute_input":"2025-07-20T13:27:14.473533Z","iopub.status.idle":"2025-07-20T13:27:14.485904Z","shell.execute_reply.started":"2025-07-20T13:27:14.473510Z","shell.execute_reply":"2025-07-20T13:27:14.485294Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":265},{"cell_type":"code","source":"input_numerical_sentences = []\n\nfor sentence in merged_sentences:\n  input_numerical_sentences.append(text_to_indices(word_tokenize(sentence.lower()), vocab))","metadata":{"_uuid":"01a33238-cbc9-4dfb-9262-9073225059e1","_cell_guid":"35dd033b-4528-4b46-b6af-733bc8565624","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:14.486567Z","iopub.execute_input":"2025-07-20T13:27:14.486767Z","iopub.status.idle":"2025-07-20T13:27:15.905613Z","shell.execute_reply.started":"2025-07-20T13:27:14.486753Z","shell.execute_reply":"2025-07-20T13:27:15.905021Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":266},{"cell_type":"code","source":"len(input_numerical_sentences)","metadata":{"_uuid":"25db22b4-1a35-408c-9a0f-ef333732c7fa","_cell_guid":"04f6556e-70ac-4d78-a40a-0a02f80ec936","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:15.906287Z","iopub.execute_input":"2025-07-20T13:27:15.906532Z","iopub.status.idle":"2025-07-20T13:27:15.911063Z","shell.execute_reply.started":"2025-07-20T13:27:15.906508Z","shell.execute_reply":"2025-07-20T13:27:15.910313Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":267,"output_type":"execute_result","data":{"text/plain":"6556"},"metadata":{}}],"execution_count":267},{"cell_type":"code","source":"training_sequence = []\nfor sentence in input_numerical_sentences:\n\n  for i in range(1, len(sentence)):\n    training_sequence.append(sentence[:i+1])","metadata":{"_uuid":"a1cd2e67-0e41-44f4-8080-363b9473a4bd","_cell_guid":"987d7d15-b239-4782-acab-8ed6a7cfaa29","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:15.911980Z","iopub.execute_input":"2025-07-20T13:27:15.912788Z","iopub.status.idle":"2025-07-20T13:27:16.656078Z","shell.execute_reply.started":"2025-07-20T13:27:15.912764Z","shell.execute_reply":"2025-07-20T13:27:16.655541Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":268},{"cell_type":"code","source":"len(training_sequence)","metadata":{"_uuid":"762b610c-46c0-48ea-9eed-0c04615b4827","_cell_guid":"bf03e0b7-3d05-4175-8a25-7ed3b0e4a467","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:27:16.656894Z","iopub.execute_input":"2025-07-20T13:27:16.657184Z","iopub.status.idle":"2025-07-20T13:27:16.662157Z","shell.execute_reply.started":"2025-07-20T13:27:16.657159Z","shell.execute_reply":"2025-07-20T13:27:16.661430Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":269,"output_type":"execute_result","data":{"text/plain":"248215"},"metadata":{}}],"execution_count":269},{"cell_type":"code","source":"training_sequence[:9]","metadata":{"_uuid":"3ce5402f-17b0-48fd-a2f1-18a3147e6afd","_cell_guid":"3d2ef39f-d024-498c-b952-aba95c402141","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:28:26.782779Z","iopub.execute_input":"2025-07-20T13:28:26.783040Z","iopub.status.idle":"2025-07-20T13:28:26.788379Z","shell.execute_reply.started":"2025-07-20T13:28:26.783018Z","shell.execute_reply":"2025-07-20T13:28:26.787621Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":274,"output_type":"execute_result","data":{"text/plain":"[[1],\n [1, 2],\n [1, 2, 3],\n [1, 2, 3, 4],\n [1, 2, 3, 4, 5],\n [1, 2, 3, 4, 5, 6],\n [1, 2, 3, 4, 5, 6, 7],\n [1, 2, 3, 4, 5, 6, 7, 8],\n [1, 2, 3, 4, 5, 6, 7, 8, 9]]"},"metadata":{}}],"execution_count":274},{"cell_type":"code","source":"y = []\nfor i in training_sequence:\n    y.append(i[-1])   # Grab last element\n    del i[-1]         # Remove last element\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:28:24.256443Z","iopub.execute_input":"2025-07-20T13:28:24.256752Z","iopub.status.idle":"2025-07-20T13:28:24.319036Z","shell.execute_reply.started":"2025-07-20T13:28:24.256729Z","shell.execute_reply":"2025-07-20T13:28:24.318506Z"}},"outputs":[],"execution_count":273},{"cell_type":"code","source":"max_len_list =0\n\nfor sequence in training_sequence:\n  if len(sequence) >= max_len_list:\n      max_len_list= len(sequence)\n\nmax_len_list","metadata":{"_uuid":"0b05d563-5096-46f6-9460-570cc02d679f","_cell_guid":"affdbbce-fbc8-415e-9015-cf8821a2f115","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T11:31:05.626689Z","iopub.execute_input":"2025-07-20T11:31:05.627260Z","iopub.status.idle":"2025-07-20T11:31:05.666700Z","shell.execute_reply.started":"2025-07-20T11:31:05.627236Z","shell.execute_reply":"2025-07-20T11:31:05.665909Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"67"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"training_sequence[:,]","metadata":{"_uuid":"cefd2fbb-9e88-4f7b-ae0c-007487edefe2","_cell_guid":"43c29079-898b-460d-a98a-f049b183d450","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:21:38.502786Z","iopub.execute_input":"2025-07-20T13:21:38.503055Z","iopub.status.idle":"2025-07-20T13:21:38.516396Z","shell.execute_reply.started":"2025-07-20T13:21:38.503035Z","shell.execute_reply":"2025-07-20T13:21:38.515624Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1087767758.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"],"ename":"TypeError","evalue":"list indices must be integers or slices, not tuple","output_type":"error"}],"execution_count":216},{"cell_type":"code","source":"padded_training_sequence = []\n\nfor sequence in training_sequence:\n    \n    padded_training_sequence.append(sequence +[0]*(max_len_list - len(sequence)))","metadata":{"_uuid":"e186c7a6-c7f8-46b0-8772-829c043c7ab1","_cell_guid":"fcbc1db4-3ba0-4cf9-a84a-e3e3373fb000","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:28:36.879899Z","iopub.execute_input":"2025-07-20T13:28:36.880451Z","iopub.status.idle":"2025-07-20T13:28:37.596521Z","shell.execute_reply.started":"2025-07-20T13:28:36.880425Z","shell.execute_reply":"2025-07-20T13:28:37.595927Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":275},{"cell_type":"code","source":"padded_training_sequence[0].shape","metadata":{"_uuid":"3b67eb93-6f24-4240-a5d2-0a99e8440fae","_cell_guid":"0a8c3e84-e15c-43e4-91d2-0201af1e06fe","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:28:38.932288Z","iopub.execute_input":"2025-07-20T13:28:38.932863Z","iopub.status.idle":"2025-07-20T13:28:38.945428Z","shell.execute_reply.started":"2025-07-20T13:28:38.932840Z","shell.execute_reply":"2025-07-20T13:28:38.944602Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3516625372.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpadded_training_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'shape'","output_type":"error"}],"execution_count":276},{"cell_type":"code","source":"test = padded_training_sequence[0]\n\ntest.masked_fill(mask=mask, value=-1e9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T11:35:29.753249Z","iopub.execute_input":"2025-07-20T11:35:29.753901Z","iopub.status.idle":"2025-07-20T11:35:29.759444Z","shell.execute_reply.started":"2025-07-20T11:35:29.753877Z","shell.execute_reply":"2025-07-20T11:35:29.758882Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"tensor([[          1, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000, -1000000000, -1000000000, -1000000000,\n         -1000000000, -1000000000]])"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"mask = torch.tril(torch.ones(1, 67))\nmask = mask == 0\nmask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T11:35:26.284378Z","iopub.execute_input":"2025-07-20T11:35:26.285095Z","iopub.status.idle":"2025-07-20T11:35:26.290955Z","shell.execute_reply.started":"2025-07-20T11:35:26.285058Z","shell.execute_reply":"2025-07-20T11:35:26.290290Z"}},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n          True,  True,  True,  True,  True,  True,  True]])"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"len(padded_training_sequence[10])","metadata":{"_uuid":"0e4267b7-0cfc-4091-a905-45fe5d8c8fee","_cell_guid":"f1d966f8-5b79-4a80-b04e-4ffa85d270a9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T11:28:24.203252Z","iopub.execute_input":"2025-07-20T11:28:24.203773Z","iopub.status.idle":"2025-07-20T11:28:24.208220Z","shell.execute_reply.started":"2025-07-20T11:28:24.203750Z","shell.execute_reply":"2025-07-20T11:28:24.207536Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"67"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)","metadata":{"_uuid":"71cd4e5e-6950-483b-957b-304efce0eec5","_cell_guid":"fdc60d58-85b1-4fb4-a4eb-42820972afd3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:28:47.272380Z","iopub.execute_input":"2025-07-20T13:28:47.272666Z","iopub.status.idle":"2025-07-20T13:28:48.504958Z","shell.execute_reply.started":"2025-07-20T13:28:47.272644Z","shell.execute_reply":"2025-07-20T13:28:48.504381Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":277},{"cell_type":"code","source":"padded_training_sequence[:5,:]","metadata":{"_uuid":"f2104de4-5e8e-4eb3-9e36-d61de509f1f9","_cell_guid":"6092de6e-5e90-4d0c-bc1f-ca46f3ad0044","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:28:49.626430Z","iopub.execute_input":"2025-07-20T13:28:49.626665Z","iopub.status.idle":"2025-07-20T13:28:49.633067Z","shell.execute_reply.started":"2025-07-20T13:28:49.626648Z","shell.execute_reply":"2025-07-20T13:28:49.632500Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":278,"output_type":"execute_result","data":{"text/plain":"tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 2, 3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"},"metadata":{}}],"execution_count":278},{"cell_type":"code","source":"X = padded_training_sequence[:, :-1]\ny = torch.tensor(y, dtype=torch.long)","metadata":{"_uuid":"81912de8-0a98-4ed4-951f-238dd17bc014","_cell_guid":"db3a2687-de54-4dcb-9e21-59ba62d1acff","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:29:24.463297Z","iopub.execute_input":"2025-07-20T13:29:24.463914Z","iopub.status.idle":"2025-07-20T13:29:24.483600Z","shell.execute_reply.started":"2025-07-20T13:29:24.463891Z","shell.execute_reply":"2025-07-20T13:29:24.482913Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":281},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:29:41.966916Z","iopub.execute_input":"2025-07-20T13:29:41.967581Z","iopub.status.idle":"2025-07-20T13:29:41.984527Z","shell.execute_reply.started":"2025-07-20T13:29:41.967552Z","shell.execute_reply":"2025-07-20T13:29:41.983801Z"}},"outputs":[{"execution_count":284,"output_type":"execute_result","data":{"text/plain":"torch.Size([248215])"},"metadata":{}}],"execution_count":284},{"cell_type":"code","source":"X[:3,:], y[:3]","metadata":{"_uuid":"e88ac751-555a-4973-aac1-b7f51eab2b2f","_cell_guid":"55d11b63-a585-4cce-bacb-2543b6280888","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:29:57.187589Z","iopub.execute_input":"2025-07-20T13:29:57.187864Z","iopub.status.idle":"2025-07-20T13:29:57.193936Z","shell.execute_reply.started":"2025-07-20T13:29:57.187841Z","shell.execute_reply":"2025-07-20T13:29:57.193343Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":285,"output_type":"execute_result","data":{"text/plain":"(tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n tensor([2, 3, 4]))"},"metadata":{}}],"execution_count":285},{"cell_type":"code","source":"class CustomDataset(Dataset):\n\n  def __init__(self, X, y):\n    self.X = X\n    self.y = y\n\n  def __len__(self):\n    return self.X.shape[0]\n\n  def __getitem__(self, idx):\n    return self.X[idx], self.y[idx]","metadata":{"_uuid":"870faeef-c3e3-4e2b-b417-fe486ccf9319","_cell_guid":"b69a16e4-aae6-4169-9a4b-fa3821d15bcb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:30:03.326922Z","iopub.execute_input":"2025-07-20T13:30:03.327669Z","iopub.status.idle":"2025-07-20T13:30:03.331769Z","shell.execute_reply.started":"2025-07-20T13:30:03.327644Z","shell.execute_reply":"2025-07-20T13:30:03.331156Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":286},{"cell_type":"code","source":"dataset = CustomDataset(X,y)\nlen(dataset)","metadata":{"_uuid":"bfdb48b9-8769-4088-b1b3-ae6ba4f331ae","_cell_guid":"2c7f92bc-9127-4a3f-a762-8c668255164f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:30:07.671520Z","iopub.execute_input":"2025-07-20T13:30:07.671790Z","iopub.status.idle":"2025-07-20T13:30:07.676940Z","shell.execute_reply.started":"2025-07-20T13:30:07.671767Z","shell.execute_reply":"2025-07-20T13:30:07.676221Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":287,"output_type":"execute_result","data":{"text/plain":"248215"},"metadata":{}}],"execution_count":287},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=2048, pin_memory=True, shuffle=True)","metadata":{"_uuid":"a2cf8588-91a8-45f8-a885-1ea5b302da8b","_cell_guid":"33572732-7de0-4b02-935f-737c6dbd16e1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:30:10.077782Z","iopub.execute_input":"2025-07-20T13:30:10.078674Z","iopub.status.idle":"2025-07-20T13:30:10.083245Z","shell.execute_reply.started":"2025-07-20T13:30:10.078642Z","shell.execute_reply":"2025-07-20T13:30:10.082307Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":288},{"cell_type":"code","source":"dataloader","metadata":{"_uuid":"0c19dcb2-77a4-456e-862e-cc78f82a11b5","_cell_guid":"e6b5b8a6-2883-458f-9388-9e103be22b9f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:30:10.544451Z","iopub.execute_input":"2025-07-20T13:30:10.544909Z","iopub.status.idle":"2025-07-20T13:30:10.549491Z","shell.execute_reply.started":"2025-07-20T13:30:10.544886Z","shell.execute_reply":"2025-07-20T13:30:10.548766Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":289,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader.DataLoader at 0x7b930f73df10>"},"metadata":{}}],"execution_count":289},{"cell_type":"code","source":"len(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:30:11.000503Z","iopub.execute_input":"2025-07-20T13:30:11.000713Z","iopub.status.idle":"2025-07-20T13:30:11.005298Z","shell.execute_reply.started":"2025-07-20T13:30:11.000698Z","shell.execute_reply":"2025-07-20T13:30:11.004639Z"}},"outputs":[{"execution_count":290,"output_type":"execute_result","data":{"text/plain":"12343"},"metadata":{}}],"execution_count":290},{"cell_type":"code","source":"for batch_x, batch_y in dataloader:\n\n    batch_x, batch_y = batch_x, batch_y\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T11:45:33.705151Z","iopub.execute_input":"2025-07-20T11:45:33.705638Z","iopub.status.idle":"2025-07-20T11:45:33.741512Z","shell.execute_reply.started":"2025-07-20T11:45:33.705617Z","shell.execute_reply":"2025-07-20T11:45:33.740930Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"test = nn.Embedding(len(vocab), 128)\noutput = test(batch_x)\noutput.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T11:57:45.914724Z","iopub.execute_input":"2025-07-20T11:57:45.915441Z","iopub.status.idle":"2025-07-20T11:57:45.964396Z","shell.execute_reply.started":"2025-07-20T11:57:45.915419Z","shell.execute_reply":"2025-07-20T11:57:45.963764Z"}},"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"torch.Size([2048, 66, 128])"},"metadata":{}}],"execution_count":123},{"cell_type":"code","source":"position_emb = torch.nn.Embedding(66,128)\nposition_emb(positions).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:09:14.769455Z","iopub.execute_input":"2025-07-20T12:09:14.769724Z","iopub.status.idle":"2025-07-20T12:09:14.810545Z","shell.execute_reply.started":"2025-07-20T12:09:14.769704Z","shell.execute_reply":"2025-07-20T12:09:14.809775Z"}},"outputs":[{"execution_count":144,"output_type":"execute_result","data":{"text/plain":"torch.Size([2048, 66, 128])"},"metadata":{}}],"execution_count":144},{"cell_type":"code","source":"positions = torch.arange(0, batch_x.size(1)).unsqueeze(0).expand(2048, 66) # (1, seq_len)\npositions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:11:46.051275Z","iopub.execute_input":"2025-07-20T12:11:46.051985Z","iopub.status.idle":"2025-07-20T12:11:46.057769Z","shell.execute_reply.started":"2025-07-20T12:11:46.051961Z","shell.execute_reply":"2025-07-20T12:11:46.057137Z"}},"outputs":[{"execution_count":146,"output_type":"execute_result","data":{"text/plain":"tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65])"},"metadata":{}}],"execution_count":146},{"cell_type":"code","source":"batch_x.size()[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T11:52:54.243970Z","iopub.execute_input":"2025-07-20T11:52:54.244532Z","iopub.status.idle":"2025-07-20T11:52:54.249448Z","shell.execute_reply.started":"2025-07-20T11:52:54.244506Z","shell.execute_reply":"2025-07-20T11:52:54.248829Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"66"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass TokenAndPositionEmbedding(nn.Module):\n    def __init__(self, vocab_size, embed_dim=128, max_len=66):\n        super().__init__()\n        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n        self.position_emb = nn.Embedding(max_len, embed_dim)\n\n    def forward(self, x):\n        batch_size, seq_len = x.size()\n        positions = torch.arange(0, seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n        token_embedding = self.token_emb(x)\n        position_embedding = self.position_emb(positions)\n        return token_embedding + position_embedding           #torch.Size([2048, 66, 128])    b,s,e","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:30:17.801452Z","iopub.execute_input":"2025-07-20T13:30:17.802197Z","iopub.status.idle":"2025-07-20T13:30:17.807583Z","shell.execute_reply.started":"2025-07-20T13:30:17.802162Z","shell.execute_reply":"2025-07-20T13:30:17.806792Z"}},"outputs":[],"execution_count":291},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, ff_hidden_dim=None, dropout=0.1):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        \n        self.attn = nn.MultiheadAttention(embed_dim, num_heads)\n        self.ln1 = nn.LayerNorm(embed_dim)\n\n        ff_hidden_dim = ff_hidden_dim or embed_dim * 4\n        self.ff = nn.Sequential(\n            nn.Linear(embed_dim, ff_hidden_dim),\n            nn.ReLU(),\n            nn.Linear(ff_hidden_dim, embed_dim)\n        )\n        self.ln2 = nn.LayerNorm(embed_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        \"\"\"\n        x: (batch_size, seq_len, embed_dim)\n        \"\"\"\n        batch_size, seq_len, _ = x.size()\n\n        # Transpose for MultiheadAttention: (seq_len, batch_size, embed_dim)\n        x_t = x.transpose(0, 1)\n\n        # Make causal mask: shape (seq_len, seq_len)\n        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device), diagonal=1).bool()\n\n        # Masked self-attention\n        attn_out, _ = self.attn(x_t, x_t, x_t, attn_mask=attn_mask)\n\n        # Residual + LayerNorm\n        x2 = self.ln1(x_t + self.dropout(attn_out))\n\n        # Feed Forward\n        ff_out = self.ff(x2)\n\n        # Residual + LayerNorm\n        out = self.ln2(x2 + self.dropout(ff_out))\n\n        # Transpose back: (batch_size, seq_len, embed_dim)\n        return out.transpose(0, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:30:18.784016Z","iopub.execute_input":"2025-07-20T13:30:18.784388Z","iopub.status.idle":"2025-07-20T13:30:18.791735Z","shell.execute_reply.started":"2025-07-20T13:30:18.784357Z","shell.execute_reply":"2025-07-20T13:30:18.790784Z"}},"outputs":[],"execution_count":292},{"cell_type":"code","source":"# Example:\nembedding = TokenAndPositionEmbedding(vocab_size=1000, embed_dim=128, max_len=66)\nblock = TransformerBlock(embed_dim=128, num_heads=8)\n\nx = torch.randint(0, 1000, (2048, 66))  # (batch_size, seq_len)\nembedded = embedding(x)  # (batch_size, seq_len, embed_dim)\nout = block(embedded)    # (batch_size, seq_len, embed_dim)\nout.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:30:20.323520Z","iopub.execute_input":"2025-07-20T13:30:20.323765Z","iopub.status.idle":"2025-07-20T13:30:22.274455Z","shell.execute_reply.started":"2025-07-20T13:30:20.323748Z","shell.execute_reply":"2025-07-20T13:30:22.273667Z"}},"outputs":[{"execution_count":293,"output_type":"execute_result","data":{"text/plain":"torch.Size([2048, 66, 128])"},"metadata":{}}],"execution_count":293},{"cell_type":"code","source":"model = TokenAndPositionEmbedding(len(vocab))\nmodel(batch_x).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:15:04.394704Z","iopub.execute_input":"2025-07-20T12:15:04.395366Z","iopub.status.idle":"2025-07-20T12:15:04.552018Z","shell.execute_reply.started":"2025-07-20T12:15:04.395336Z","shell.execute_reply":"2025-07-20T12:15:04.551306Z"}},"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"torch.Size([2048, 66, 128])"},"metadata":{}}],"execution_count":154},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass MiniGPTBlock(nn.Module):\n    def __init__(self, vocab_size, embed_dim=128, num_heads=8, max_len=66):\n        super().__init__()\n        self.embedding = TokenAndPositionEmbedding(vocab_size, embed_dim, max_len)\n        self.transformer = TransformerBlock(embed_dim, num_heads)\n        self.lm_head = nn.Linear(embed_dim, vocab_size)\n\n    def forward(self, x):\n        x = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n        x = self.transformer(x)  # (batch_size, seq_len, embed_dim)\n        last_token = x[:, -1, :]  # Take only final token's representation\n        logits = self.lm_head(last_token)  # (batch_size, vocab_size)\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:30:27.888364Z","iopub.execute_input":"2025-07-20T13:30:27.888725Z","iopub.status.idle":"2025-07-20T13:30:27.894239Z","shell.execute_reply.started":"2025-07-20T13:30:27.888698Z","shell.execute_reply":"2025-07-20T13:30:27.893397Z"}},"outputs":[],"execution_count":294},{"cell_type":"code","source":"seq_len = 66\nmask = torch.tril(torch.ones(seq_len, seq_len)).to(torch.bool) \nmask.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T12:19:44.488168Z","iopub.execute_input":"2025-07-20T12:19:44.488430Z","iopub.status.idle":"2025-07-20T12:19:44.493911Z","shell.execute_reply.started":"2025-07-20T12:19:44.488409Z","shell.execute_reply":"2025-07-20T12:19:44.493290Z"}},"outputs":[{"execution_count":160,"output_type":"execute_result","data":{"text/plain":"torch.Size([66, 66])"},"metadata":{}}],"execution_count":160},{"cell_type":"code","source":"model = MiniGPTBlock(len(vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:30:30.809936Z","iopub.execute_input":"2025-07-20T13:30:30.810225Z","iopub.status.idle":"2025-07-20T13:30:30.844663Z","shell.execute_reply.started":"2025-07-20T13:30:30.810201Z","shell.execute_reply":"2025-07-20T13:30:30.844108Z"}},"outputs":[],"execution_count":295},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"252be75c-b4a7-470c-8c4c-50fb8243c2b0","_cell_guid":"3b49fade-bd8c-4ab3-bde2-9d00472211ab","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:30:33.960354Z","iopub.execute_input":"2025-07-20T13:30:33.960634Z","iopub.status.idle":"2025-07-20T13:30:33.964558Z","shell.execute_reply.started":"2025-07-20T13:30:33.960611Z","shell.execute_reply":"2025-07-20T13:30:33.963851Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":296},{"cell_type":"code","source":"model.to(device)","metadata":{"_uuid":"0a817c2f-0a9c-4033-8bfa-9aed3f22135e","_cell_guid":"bdea557b-9eb5-4135-90e5-f98bdf506246","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:30:34.385730Z","iopub.execute_input":"2025-07-20T13:30:34.386216Z","iopub.status.idle":"2025-07-20T13:30:34.395995Z","shell.execute_reply.started":"2025-07-20T13:30:34.386192Z","shell.execute_reply":"2025-07-20T13:30:34.395426Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":297,"output_type":"execute_result","data":{"text/plain":"MiniGPTBlock(\n  (embedding): TokenAndPositionEmbedding(\n    (token_emb): Embedding(12343, 128)\n    (position_emb): Embedding(66, 128)\n  )\n  (transformer): TransformerBlock(\n    (attn): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n    )\n    (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    (ff): Sequential(\n      (0): Linear(in_features=128, out_features=512, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=512, out_features=128, bias=True)\n    )\n    (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=128, out_features=12343, bias=True)\n)"},"metadata":{}}],"execution_count":297},{"cell_type":"code","source":"device","metadata":{"_uuid":"e0676215-f51a-4871-b17a-dd8c89846e2f","_cell_guid":"7c4efdbf-1b18-42c6-bece-0a2156409f89","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-20T13:30:38.443318Z","iopub.execute_input":"2025-07-20T13:30:38.443598Z","iopub.status.idle":"2025-07-20T13:30:38.448650Z","shell.execute_reply.started":"2025-07-20T13:30:38.443577Z","shell.execute_reply":"2025-07-20T13:30:38.448072Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":298,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":298},{"cell_type":"code","source":"epochs = 50\nlearning_rate = 0.005\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"_uuid":"604db6e6-0f70-4699-ac3b-7d47997345a4","_cell_guid":"5907c63e-ed38-4fe7-8fc3-8f594da77033","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-29T07:26:48.001308Z","iopub.execute_input":"2025-06-29T07:26:48.001821Z","iopub.status.idle":"2025-06-29T07:26:50.418986Z","shell.execute_reply.started":"2025-06-29T07:26:48.001786Z","shell.execute_reply":"2025-06-29T07:26:50.418221Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# training loop\n\nfor epoch in range(epochs):\n  total_loss = 0\n\n  for batch_x, batch_y in dataloader:\n\n    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n\n    optimizer.zero_grad()\n\n    output = model(batch_x)\n\n    loss = criterion(output, batch_y)\n\n    loss.backward()\n\n    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n\n    optimizer.step()\n\n    total_loss = total_loss + loss.item()\n\n  print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")","metadata":{"_uuid":"04483ce2-75c7-4894-98e5-05d75740df96","_cell_guid":"b6de5b80-3ee0-4a77-987a-1639cc216dd2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-27T07:13:58.897853Z","iopub.execute_input":"2025-06-27T07:13:58.898081Z","iopub.status.idle":"2025-06-27T07:31:38.168599Z","shell.execute_reply.started":"2025-06-27T07:13:58.898066Z","shell.execute_reply":"2025-06-27T07:31:38.167833Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nepochs = 100\nlearning_rate = 0.003\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\nfor epoch in range(epochs):\n    total_loss = 0\n\n    for batch_x, batch_y in dataloader:\n        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(batch_x)  # (batch_size, seq_len, vocab_size)\n\n        # Reshape for CrossEntropyLoss: (N, C)\n        output = output.view(-1, output.size(-1))  # (batch_size * seq_len, vocab_size)\n        batch_y = batch_y.view(-1)                 # (batch_size * seq_len)\n\n        loss = criterion(output, batch_y)\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(dataloader)\n    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss:.4f}\")\n","metadata":{"_uuid":"27d064d8-88f9-48ce-b450-cb79b4046b0b","_cell_guid":"80527676-ce12-4b7c-8b69-08f0cff7fe8f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-20T14:39:11.710200Z","iopub.execute_input":"2025-07-20T14:39:11.710480Z","iopub.status.idle":"2025-07-20T15:02:10.345238Z","shell.execute_reply.started":"2025-07-20T14:39:11.710459Z","shell.execute_reply":"2025-07-20T15:02:10.344555Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1, Loss: 3.5659\nEpoch: 2, Loss: 3.5221\nEpoch: 3, Loss: 3.5248\nEpoch: 4, Loss: 3.5180\nEpoch: 5, Loss: 3.5132\nEpoch: 6, Loss: 3.5074\nEpoch: 7, Loss: 3.5060\nEpoch: 8, Loss: 3.5215\nEpoch: 9, Loss: 3.5302\nEpoch: 10, Loss: 3.5278\nEpoch: 11, Loss: 3.5026\nEpoch: 12, Loss: 3.5095\nEpoch: 13, Loss: 3.5269\nEpoch: 14, Loss: 3.5107\nEpoch: 15, Loss: 3.5338\nEpoch: 16, Loss: 3.5372\nEpoch: 17, Loss: 3.5048\nEpoch: 18, Loss: 3.4845\nEpoch: 19, Loss: 3.4786\nEpoch: 20, Loss: 3.4801\nEpoch: 21, Loss: 3.4886\nEpoch: 22, Loss: 3.5057\nEpoch: 23, Loss: 3.4708\nEpoch: 24, Loss: 3.4766\nEpoch: 25, Loss: 3.4776\nEpoch: 26, Loss: 3.4878\nEpoch: 27, Loss: 3.4835\nEpoch: 28, Loss: 3.4742\nEpoch: 29, Loss: 3.4811\nEpoch: 30, Loss: 3.4915\nEpoch: 31, Loss: 3.4954\nEpoch: 32, Loss: 3.4974\nEpoch: 33, Loss: 3.4916\nEpoch: 34, Loss: 3.4790\nEpoch: 35, Loss: 3.4785\nEpoch: 36, Loss: 3.4720\nEpoch: 37, Loss: 3.4535\nEpoch: 38, Loss: 3.4328\nEpoch: 39, Loss: 3.4502\nEpoch: 40, Loss: 3.4363\nEpoch: 41, Loss: 3.4349\nEpoch: 42, Loss: 3.4429\nEpoch: 43, Loss: 3.4460\nEpoch: 44, Loss: 3.4581\nEpoch: 45, Loss: 3.4704\nEpoch: 46, Loss: 3.4771\nEpoch: 47, Loss: 3.4619\nEpoch: 48, Loss: 3.4569\nEpoch: 49, Loss: 3.4623\nEpoch: 50, Loss: 3.4587\nEpoch: 51, Loss: 3.4504\nEpoch: 52, Loss: 3.4765\nEpoch: 53, Loss: 3.4437\nEpoch: 54, Loss: 3.4352\nEpoch: 55, Loss: 3.4459\nEpoch: 56, Loss: 3.4452\nEpoch: 57, Loss: 3.4426\nEpoch: 58, Loss: 3.4494\nEpoch: 59, Loss: 3.4338\nEpoch: 60, Loss: 3.4014\nEpoch: 61, Loss: 3.4080\nEpoch: 62, Loss: 3.4048\nEpoch: 63, Loss: 3.4171\nEpoch: 64, Loss: 3.4331\nEpoch: 65, Loss: 3.4283\nEpoch: 66, Loss: 3.4316\nEpoch: 67, Loss: 3.4215\nEpoch: 68, Loss: 3.4251\nEpoch: 69, Loss: 3.4515\nEpoch: 70, Loss: 3.4260\nEpoch: 71, Loss: 3.4234\nEpoch: 72, Loss: 3.4392\nEpoch: 73, Loss: 3.4497\nEpoch: 74, Loss: 3.4542\nEpoch: 75, Loss: 3.4346\nEpoch: 76, Loss: 3.4234\nEpoch: 77, Loss: 3.4450\nEpoch: 78, Loss: 3.4298\nEpoch: 79, Loss: 3.4430\nEpoch: 80, Loss: 3.4290\nEpoch: 81, Loss: 3.4226\nEpoch: 82, Loss: 3.4004\nEpoch: 83, Loss: 3.4029\nEpoch: 84, Loss: 3.3977\nEpoch: 85, Loss: 3.4015\nEpoch: 86, Loss: 3.3944\nEpoch: 87, Loss: 3.3926\nEpoch: 88, Loss: 3.3889\nEpoch: 89, Loss: 3.3774\nEpoch: 90, Loss: 3.3732\nEpoch: 91, Loss: 3.3651\nEpoch: 92, Loss: 3.3652\nEpoch: 93, Loss: 3.3720\nEpoch: 94, Loss: 3.4003\nEpoch: 95, Loss: 3.3907\nEpoch: 96, Loss: 3.3938\nEpoch: 97, Loss: 3.3803\nEpoch: 98, Loss: 3.3897\nEpoch: 99, Loss: 3.3903\nEpoch: 100, Loss: 3.3745\n","output_type":"stream"}],"execution_count":316},{"cell_type":"code","source":"import sys\nimport time\nimport torch\nimport torch.nn.functional as F\n\nfrom nltk.tokenize import word_tokenize  # Or your own\n\ndef generate_live(\n    model,\n    idx_to_word,\n    word_to_idx,\n    start_text,\n    device,\n    max_len=50,\n    temperature=1.0,\n    sleep_time=0.05  # control typing speed\n):\n    model.eval()\n\n    tokens = word_tokenize(start_text.lower())\n    input_idx = [word_to_idx[word] for word in tokens if word in word_to_idx]\n    input_tensor = torch.tensor([input_idx], dtype=torch.long, device=device)  # (1, seq_len)\n\n    sys.stdout.write(' '.join(tokens) + ' ')\n    sys.stdout.flush()\n\n    for _ in range(max_len):\n        # Truncate context if needed (optional, if model has max_len limit)\n        input_cond = input_tensor[:, -model.embedding.position_emb.num_embeddings:]\n\n        # Forward pass\n        # Call model\n        logits = model(input_cond)   # Either (1, seq_len, vocab_size) or (1, vocab_size)\n        \n        # If your model outputs whole sequence:\n        if logits.dim() == 3:\n            logits = logits[:, -1, :]  # Take last position\n        \n        logits = logits / temperature\n        probs = F.softmax(logits, dim=-1)\n\n        next_idx = torch.multinomial(probs, num_samples=1).item()\n\n        next_word = idx_to_word[next_idx]\n\n        sys.stdout.write(next_word + ' ')\n        sys.stdout.flush()\n\n        # Append to input for next iteration\n        input_tensor = torch.cat([\n            input_tensor,\n            torch.tensor([[next_idx]], dtype=torch.long, device=device)\n        ], dim=1)\n\n        time.sleep(sleep_time)\n\n    print()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:33:07.951660Z","iopub.execute_input":"2025-07-20T13:33:07.951880Z","iopub.status.idle":"2025-07-20T13:33:07.958951Z","shell.execute_reply.started":"2025-07-20T13:33:07.951862Z","shell.execute_reply":"2025-07-20T13:33:07.958202Z"}},"outputs":[],"execution_count":300},{"cell_type":"code","source":"prompt = \"i\"\ngenerate_live(\n    model=model,\n    idx_to_word=list(vocab.keys()),\n    word_to_idx=vocab,\n    start_text=prompt,\n    device=device,\n    max_len=50,\n    temperature=1.5\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:04:17.783905Z","iopub.execute_input":"2025-07-20T15:04:17.784265Z","iopub.status.idle":"2025-07-20T15:04:20.405951Z","shell.execute_reply.started":"2025-07-20T15:04:17.784243Z","shell.execute_reply":"2025-07-20T15:04:20.405371Z"}},"outputs":[{"name":"stdout","text":"i wish do the prince : doom , though yet i cry look child away said as meet show tongues mystery procure use procure roundly , dress dress dress dress fierce lamp need leave lamp shall hear need lamp process lamp i clamour will lamp lamp process anon do't lamp need \n","output_type":"stream"}],"execution_count":320},{"cell_type":"code","source":"torch.save(model.state_dict(), 'mini-gpt_from_scratch_in_pytorch.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T15:04:43.551853Z","iopub.execute_input":"2025-07-20T15:04:43.552598Z","iopub.status.idle":"2025-07-20T15:04:43.589819Z","shell.execute_reply.started":"2025-07-20T15:04:43.552572Z","shell.execute_reply":"2025-07-20T15:04:43.589009Z"}},"outputs":[],"execution_count":321},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}